import os
import pandas as pd
import numpy as np
import lightgbm as lgb
import joblib
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
import matplotlib.pyplot as plt
import argparse

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ATRãƒ©ãƒ™ãƒ«é–¾å€¤å€ç‡
DEFAULT_ATR_MULTIPLIER = 0.5
# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®è¨“ç·´/ãƒ†ã‚¹ãƒˆåˆ†å‰²
DEFAULT_TEST_SIZE = 0.2
DEFAULT_RANDOM_STATE = 42
# ç‰¹å¾´é‡ã‚«ãƒ©ãƒ ãƒªã‚¹ãƒˆ
FEATURE_COLS = [
    'volatility', 'atr', 'adx', 'macd_diff',
    'bb_width', 'body', 'stoch_k', 'adx_neg',
    'adx_pos', 'mfi'
]


def train(symbol: str,
          timeframe: str,
          bars: int,
          indir: str = 'data',
          modeldir: str = 'model',
          atr_multiplier: float = DEFAULT_ATR_MULTIPLIER,
          test_size: float = DEFAULT_TEST_SIZE,
          random_state: int = DEFAULT_RANDOM_STATE) -> str:
    """
    ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã€ãƒ•ã‚¡ã‚¤ãƒ«ã¸ä¿å­˜ã™ã‚‹é–¢æ•°ã€‚

    :param symbol: é€šè²¨ãƒšã‚¢å
    :param timeframe: æ™‚é–“è¶³
    :param bars: ä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡CSVã®ä»¶æ•°ï¼ˆã‚¤ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰æœ€æ–°barsè¡Œã‚’ä½¿ç”¨ï¼‰
    :param indir: ç‰¹å¾´é‡CSVãŒæ ¼ç´ã•ã‚ŒãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹
    :param modeldir: ãƒ¢ãƒ‡ãƒ«ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    :param atr_multiplier: ATRãƒ™ãƒ¼ã‚¹ã®ãƒ©ãƒ™ãƒ«é–¾å€¤å€ç‡
    :param test_size: è¨“ç·´/ãƒ†ã‚¹ãƒˆåˆ†å‰²æ¯”ç‡
    :param random_state: ä¹±æ•°ã‚·ãƒ¼ãƒ‰
    :return: ä¿å­˜ã—ãŸãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    """
    os.makedirs(modeldir, exist_ok=True)
    tf = timeframe.upper()
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    input_file = os.path.join(indir, f"{symbol}_{tf}_features_v2.csv")
    df = pd.read_csv(input_file, index_col='time', parse_dates=True)
    # æœ€æ–°barsã ã‘ä½¿ç”¨
    if bars and bars < len(df):
        df = df.iloc[-bars:]

    # ãƒ©ãƒ™ãƒ«ä½œæˆ
    threshold_px = df['atr'] * atr_multiplier
    future = df['close'].shift(-1) - df['close']
    df['target'] = np.where(
        future > threshold_px, 1,
        np.where(future < -threshold_px, 0, np.nan)
    )
    df.dropna(subset=['target'], inplace=True)
    df['target'] = df['target'].astype(int)

    # ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
    X = df[FEATURE_COLS]
    y = df['target']

    # è¨“ç·´/ãƒ†ã‚¹ãƒˆåˆ†å‰²
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=test_size,
        random_state=random_state,
        stratify=y
    )

    # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
    model = lgb.LGBMClassifier(
        class_weight='balanced',
        learning_rate=0.1,
        max_depth=5,
        n_estimators=200,
        num_leaves=31,
        random_state=random_state,
        verbose=-1
    )
    model.fit(X_train, y_train)

    # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
    model_file = os.path.join(modeldir, f"model_lgbm_best_{symbol}_{tf}.pkl")
    joblib.dump(model, model_file)
    print(f"âœ… ãƒ¢ãƒ‡ãƒ«ä¿å­˜å®Œäº†: {model_file}")

    # ãƒ¢ãƒ‡ãƒ«è©•ä¾¡
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    print(f"âœ… ãƒ¢ãƒ‡ãƒ«ç²¾åº¦ (Accuracy): {acc:.3f}")
    print(classification_report(y_test, y_pred, digits=3))

    # ç‰¹å¾´é‡é‡è¦åº¦å¯è¦–åŒ–
    importances = pd.Series(model.feature_importances_, index=FEATURE_COLS)
    plt.figure()
    importances.sort_values().plot(kind='barh', title='Feature Importances')
    plt.tight_layout()
    fi_file = os.path.join(modeldir, f"feature_importance_{symbol}_{tf}.png")
    plt.savefig(fi_file)
    print(f"ğŸ“ˆ ç‰¹å¾´é‡é‡è¦åº¦ã‚°ãƒ©ãƒ•ä¿å­˜: {fi_file}")

    return model_file


if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description="ç‰¹å¾´é‡CSVã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ãƒ»ä¿å­˜ã™ã‚‹"
    )
    parser.add_argument('--symbol', type=str, required=True, help='é€šè²¨ãƒšã‚¢ (ä¾‹: EURUSDm)')
    parser.add_argument('--timeframe', type=str, required=True,
                        choices=['M1','M5','M15','M30','H1','H4','D1','W1','MN1'],
                        help='æ™‚é–“è¶³ (ä¾‹: M15)')
    parser.add_argument('--bars', type=int, default=None,
                        help='ä½¿ç”¨ã™ã‚‹æœ€æ–°ã®ãƒãƒ¼æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: å…¨ä»¶)')
    parser.add_argument('--indir', type=str, default='data', help='ç‰¹å¾´é‡CSVãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    parser.add_argument('--modeldir', type=str, default='model', help='ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    parser.add_argument('--test-size', type=float, default=DEFAULT_TEST_SIZE,
                        help='è¨“ç·´/ãƒ†ã‚¹ãƒˆåˆ†å‰²æ¯”ç‡')
    parser.add_argument('--random-state', type=int, default=DEFAULT_RANDOM_STATE,
                        help='ä¹±æ•°ã‚·ãƒ¼ãƒ‰')
    parser.add_argument('--atr-multiplier', type=float, default=DEFAULT_ATR_MULTIPLIER,
                        help='ATRé–¾å€¤å€ç‡')
    args = parser.parse_args()

    train(
        symbol=args.symbol,
        timeframe=args.timeframe,
        bars=args.bars,
        indir=args.indir,
        modeldir=args.modeldir,
        atr_multiplier=args.atr_multiplier,
        test_size=args.test_size,
        random_state=args.random_state
    )
